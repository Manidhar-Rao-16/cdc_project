{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e430b90-0a31-43d9-a262-eea6e5ad971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/01/26 16:02:08 WARN Utils: Your hostname, Vardhinenis-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 192.168.0.31 instead (on interface en0)\n",
      "26/01/26 16:02:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "26/01/26 16:02:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CDC_Employee_Project\") \\\n",
    "    .config(\n",
    "        \"spark.jars\",\n",
    "        \"/Users/manidharrao16/docs/manidocs/pyspark/jdbc/mysql-connector-j-8.4.0/mysql-connector-j-8.4.0.jar\"\n",
    "    ) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc13a252-db91-436f-bc31-ac8830e3c818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+---------+------+\n",
      "|emp_id|emp_name|   dept|     city|salary|\n",
      "+------+--------+-------+---------+------+\n",
      "|   101|    Raju|     IT|Hyderabad| 50000|\n",
      "|   102|  Anitha|     HR|Bangalore| 45000|\n",
      "|   103|  Suresh|     IT|  Chennai| 55000|\n",
      "|   104|   Priya|Finance|Hyderabad| 60000|\n",
      "|   105|  Ramesh|     HR|Hyderabad| 42000|\n",
      "|   106|   Kiran|     IT|Hyderabad| 52000|\n",
      "|   107|    Neha|Finance|Hyderabad| 58000|\n",
      "|   108|   Arjun|     IT|Bangalore| 54000|\n",
      "|   109|   Divya|     HR|  Chennai| 46000|\n",
      "|   110|    Amit|     IT|Hyderabad| 51000|\n",
      "|   111|   Sneha|Finance|Hyderabad| 62000|\n",
      "|   112|   Vikas|     IT|Hyderabad| 53000|\n",
      "|   113|   Pooja|     HR|Hyderabad| 44000|\n",
      "|   114|   Manoj|     IT|Bangalore| 56000|\n",
      "|   115|   Kavya|Finance|Hyderabad| 59000|\n",
      "|   116|  Sanjay|     HR|Hyderabad| 43000|\n",
      "|   117|    Ritu|     IT|Hyderabad| 57000|\n",
      "|   118|  Nikhil|     IT|Bangalore| 54500|\n",
      "|   119|   Meena|     HR|Hyderabad| 45500|\n",
      "|   120|   Varun|Finance|Bangalore| 61000|\n",
      "+------+--------+-------+---------+------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jdbc_url = \"jdbc:mysql://127.0.0.1:3306/company_db\"\n",
    "properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"Manidharrao@777\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "employee_df = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"employee_data\",\n",
    "    properties=properties\n",
    ")\n",
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310ff56b-5488-45a7-8d90-a040ce8d50af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+---------+---------+\n",
      "|emp_id|emp_name|salary|     city|operation|\n",
      "+------+--------+------+---------+---------+\n",
      "|   102|  Anitha| 48000|Bangalore|   UPDATE|\n",
      "|   107|    Neha| 60000|    Noida|   UPDATE|\n",
      "|   119|   Meena| 47000| Warangal|   UPDATE|\n",
      "|   126|  Rajesh| 42000|Hyderabad|   UPDATE|\n",
      "|   127|   Suman| 50000|Bangalore|   UPDATE|\n",
      "|   128| Karthik| 53000|  Chennai|   UPDATE|\n",
      "|   105|  Ramesh|  NULL|     Pune|   DELETE|\n",
      "|   113|   Pooja|  NULL|Hyderabad|   DELETE|\n",
      "|   121|  Deepak|  NULL|  Chennai|   DELETE|\n",
      "+------+--------+------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdc_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"/Users/manidharrao16/docs/manidocs/pyspark/employees_cdc.csv\")\n",
    "cdc_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a04b2a4-4c51-4c22-bf99-f7befcfe220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate CDC Operations (UPDATE / INSERT / DELETE)\n",
    "\n",
    "from pyspark.sql.functions import col, coalesce, lit\n",
    "\n",
    "updates_df = cdc_df.filter(col(\"operation\") == \"UPDATE\")\n",
    "inserts_df = cdc_df.filter(col(\"operation\") == \"INSERT\")\n",
    "deletes_df = cdc_df.filter(col(\"operation\") == \"DELETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc31def-df89-4369-946d-ac16e1641eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply UPDATE Logic\n",
    "# Update salary and city only if present in CDC file.\n",
    "\n",
    "updated_employee_df = employee_df.alias(\"emp\") \\\n",
    "    .join(updates_df.alias(\"cdc\"), \"emp_id\", \"left\") \\\n",
    "    .select(\n",
    "        col(\"emp_id\"),\n",
    "        col(\"emp.emp_name\"),\n",
    "        col(\"emp.dept\"),\n",
    "        coalesce(col(\"cdc.city\"), col(\"emp.city\")).alias(\"city\"),#take new value if available, else keep old value\n",
    "        coalesce(col(\"cdc.salary\"), col(\"emp.salary\")).alias(\"salary\")\n",
    "    )\n",
    "# coalesce() means: \"take the first value that is NOT empty (NOT NULL)\"\n",
    "\n",
    "# If CDC file gives new city → update it\n",
    "# If CDC file city is empty → keep old city from employee table\n",
    "# coalesce(col(\"cdc.city\"), col(\"emp.city\")).alias(\"city\")\n",
    "# If CDC file gives new salary → update it\n",
    "# If CDC file salary is empty → keep old salary from employee table\n",
    "# coalesce(col(\"cdc.salary\"), col(\"emp.salary\")).alias(\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258b93d4-2a8a-4ec2-9829-bf6e788a5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DELETE Logic\n",
    "# Remove employees whose emp_id exists in DELETE records.\n",
    "after_delete_df = updated_employee_df.join(\n",
    "    deletes_df.select(\"emp_id\"),\n",
    "    on=\"emp_id\",\n",
    "    how=\"left_anti\"\n",
    ")\n",
    "# left_anti = Give me rows from left side that do NOT exist in delete list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5ba348a-ceea-4b50-903b-3dea8a489438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply INSERT Logic\n",
    "# Create new employee records.\n",
    "new_employees_df = inserts_df.select(\n",
    "    col(\"emp_id\"),\n",
    "    lit(\"New Employee\").alias(\"emp_name\"),\n",
    "    lit(\"NA\").alias(\"dept\"),\n",
    "    col(\"city\"),\n",
    "    col(\"salary\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b088d17-7b90-45af-997f-828a8df1511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------+---------+------+\n",
      "|emp_id|emp_name|   dept|     city|salary|\n",
      "+------+--------+-------+---------+------+\n",
      "|   101|    Raju|     IT|Hyderabad| 50000|\n",
      "|   102|  Anitha|     HR|Bangalore| 48000|\n",
      "|   103|  Suresh|     IT|  Chennai| 55000|\n",
      "|   104|   Priya|Finance|Hyderabad| 60000|\n",
      "|   106|   Kiran|     IT|Hyderabad| 52000|\n",
      "|   107|    Neha|Finance|    Noida| 60000|\n",
      "|   108|   Arjun|     IT|Bangalore| 54000|\n",
      "|   109|   Divya|     HR|  Chennai| 46000|\n",
      "|   110|    Amit|     IT|Hyderabad| 51000|\n",
      "|   111|   Sneha|Finance|Hyderabad| 62000|\n",
      "|   112|   Vikas|     IT|Hyderabad| 53000|\n",
      "|   114|   Manoj|     IT|Bangalore| 56000|\n",
      "|   115|   Kavya|Finance|Hyderabad| 59000|\n",
      "|   116|  Sanjay|     HR|Hyderabad| 43000|\n",
      "|   117|    Ritu|     IT|Hyderabad| 57000|\n",
      "|   118|  Nikhil|     IT|Bangalore| 54500|\n",
      "|   119|   Meena|     HR| Warangal| 47000|\n",
      "|   120|   Varun|Finance|Bangalore| 61000|\n",
      "|   122|  Swathi|     HR|   Mumbai| 47000|\n",
      "|   123|    Ajay|     IT|Hyderabad| 53500|\n",
      "|   124| Lavanya|Finance|Hyderabad| 60000|\n",
      "|   125|   Rohit|     IT|    Delhi| 55000|\n",
      "+------+--------+-------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final CDC Result\n",
    "# Combine updated + inserted records.\n",
    "final_df = after_delete_df.unionByName(new_employees_df)\n",
    "final_df.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92a08c2c-80d9-4329-ae57-2823e182ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.write.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"employee_target\",\n",
    "    mode=\"overwrite\",\n",
    "    properties=properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debad547-c1c5-4176-bc9f-9d11fda0122b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
